{"cells":[{"cell_type":"markdown","id":"a67eded3","metadata":{"id":"a67eded3"},"source":["# Check GPU"]},{"cell_type":"code","execution_count":null,"id":"0a331a01-74a9-4f4b-a198-7e15965cd456","metadata":{"id":"0a331a01-74a9-4f4b-a198-7e15965cd456","outputId":"e5160d57-5e64-4e4a-b327-8fd8a3dc1015"},"outputs":[{"name":"stdout","output_type":"stream","text":["1\n","True\n","1.13.1\n","0\n"]}],"source":["import torch\n","print(torch.cuda.device_count()) \n","print(torch.cuda.is_available())\n","print(torch.__version__)\n","print(torch.cuda.current_device())"]},{"cell_type":"markdown","id":"872f96ee-abd0-4070-bd67-08c24f08eda9","metadata":{"tags":[],"id":"872f96ee-abd0-4070-bd67-08c24f08eda9"},"source":["# Fine-tune Whisper"]},{"cell_type":"markdown","id":"e18e4a64-1483-49c6-871e-b4d0e930e619","metadata":{"id":"e18e4a64-1483-49c6-871e-b4d0e930e619"},"source":["## Prepare Data and Model"]},{"cell_type":"markdown","id":"b6d0a818-c6ad-488e-910c-ff32dcfa6356","metadata":{"id":"b6d0a818-c6ad-488e-910c-ff32dcfa6356"},"source":["### Load Model"]},{"cell_type":"code","execution_count":null,"id":"311c3d35-191b-4900-a8b3-f4a4002133dc","metadata":{"id":"311c3d35-191b-4900-a8b3-f4a4002133dc"},"outputs":[],"source":["from transformers import WhisperForConditionalGeneration\n","\n","model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")"]},{"cell_type":"markdown","id":"a720113a-ecf3-40b3-bb46-e662517cfaf1","metadata":{"id":"a720113a-ecf3-40b3-bb46-e662517cfaf1"},"source":["### Load Datasets"]},{"cell_type":"code","execution_count":null,"id":"a188c741-6330-489e-ae4f-c26b20b78788","metadata":{"id":"a188c741-6330-489e-ae4f-c26b20b78788"},"outputs":[],"source":["AUDIO_COLUMN_NAME = \"audio\"\n","TEXT_COLUMN_NAME = \"sentence\""]},{"cell_type":"code","execution_count":null,"id":"dfe80a2b-e464-4555-a18b-b69e0f09a87c","metadata":{"id":"dfe80a2b-e464-4555-a18b-b69e0f09a87c"},"outputs":[],"source":["from datasets import Audio\n","\n","def normalize_dataset(ds, audio_column_name=None, text_column_name=None):\n","\n","    if audio_column_name is not None and audio_column_name != AUDIO_COLUMN_NAME:\n","        ds = ds.rename_column(audio_column_name, AUDIO_COLUMN_NAME)\n","\n","    if text_column_name is not None and text_column_name != TEXT_COLUMN_NAME:\n","        ds = ds.rename_column(text_column_name, TEXT_COLUMN_NAME)\n","\n","    # resample to the same sampling rate\n","    ds = ds.cast_column(\"audio\", Audio(sampling_rate=16_000))\n","\n","    # normalise columns to [\"audio\", \"sentence\"]\n","    ds = ds.remove_columns(set(ds.features.keys()) - set([AUDIO_COLUMN_NAME, TEXT_COLUMN_NAME]))\n","    \n","    return ds"]},{"cell_type":"markdown","id":"0818c090","metadata":{"id":"0818c090"},"source":["### Use huggingface API"]},{"cell_type":"code","execution_count":null,"id":"ee9df9cb","metadata":{"colab":{"referenced_widgets":["97390ead08f548a791004b7143f4aa98"]},"id":"ee9df9cb","outputId":"10d58432-c931-4cad-daf9-a289287c15a0"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"97390ead08f548a791004b7143f4aa98","version_major":2,"version_minor":0},"text/plain":["VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"]},"metadata":{},"output_type":"display_data"}],"source":["from huggingface_hub import notebook_login\n","\n","notebook_login()"]},{"cell_type":"code","execution_count":null,"id":"796085e6","metadata":{"id":"796085e6"},"outputs":[],"source":["from datasets import load_dataset, DatasetDict\n","\n","datasets = DatasetDict()"]},{"cell_type":"code","execution_count":null,"id":"5c596a1f","metadata":{"id":"5c596a1f","outputId":"a89ae1c4-dbf3-4f74-9a63-9e33d0a8ac3b"},"outputs":[{"name":"stderr","output_type":"stream","text":["Found cached dataset common_voice_11_0 (/home/user/.cache/huggingface/datasets/mozilla-foundation___common_voice_11_0/fr/11.0.0/2c65b95d99ca879b1b1074ea197b65e0497848fd697fdb0582e0f6b75b6f4da0)\n"]}],"source":["dataset = load_dataset(\"mozilla-foundation/common_voice_11_0\", \"fr\", split=\"test\", use_auth_token=True)\n","dataset = normalize_dataset(dataset)"]},{"cell_type":"code","execution_count":null,"id":"1d8f6cb3","metadata":{"id":"1d8f6cb3","outputId":"4f41b4a1-c463-4635-f136-59dd669d4ac8"},"outputs":[{"data":{"text/plain":["Dataset({\n","    features: ['audio', 'sentence'],\n","    num_rows: 16089\n","})"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["dataset"]},{"cell_type":"markdown","id":"915e81e0","metadata":{"id":"915e81e0"},"source":["### Split dataset into train and test"]},{"cell_type":"code","execution_count":null,"id":"f44bd5b1","metadata":{"id":"f44bd5b1"},"outputs":[],"source":["num_train_examples = 200\n","num_test_examples = 50\n","\n","datasets[\"train\"] = dataset.select(range(num_train_examples))\n","datasets[\"eval\"] =  dataset.select(range(num_test_examples))"]},{"cell_type":"code","execution_count":null,"id":"9f414bb1","metadata":{"id":"9f414bb1","outputId":"16b19542-a15d-480d-ac4e-4078a1a7f797"},"outputs":[{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['audio', 'sentence'],\n","        num_rows: 200\n","    })\n","    eval: Dataset({\n","        features: ['audio', 'sentence'],\n","        num_rows: 50\n","    })\n","})"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["datasets"]},{"cell_type":"markdown","source":["# Data Augmentation"],"metadata":{"id":"HLoS2_GUlSEb"},"id":"HLoS2_GUlSEb"},{"cell_type":"code","source":["from audiomentations import (\n","    AddBackgroundNoise,\n","    AddGaussianNoise,\n","    Compose,\n","    Gain,\n","    OneOf,\n","    PitchShift,\n","    PolarityInversion,\n","    TimeStretch,\n",")"],"metadata":{"id":"GP8k92m7lUNV"},"id":"GP8k92m7lUNV","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### define augmentation"],"metadata":{"id":"XCN1VMXnmnUV"},"id":"XCN1VMXnmnUV"},{"cell_type":"code","source":["augmentation = Compose(\n","    [\n","        TimeStretch(min_rate=0.9, max_rate=1.1, p=0.2, leave_length_unchanged=False),\n","    ]\n",")"],"metadata":{"id":"1IU3IoHJmLNJ"},"id":"1IU3IoHJmLNJ","execution_count":null,"outputs":[]},{"cell_type":"code","source":["def augment_dataset(batch):\n","    # load and (possibly) resample audio data to 16kHz\n","    sample = batch[AUDIO_COLUMN_NAME]\n","\n","    # apply augmentation\n","    augmented_waveform = augmentation(sample[\"array\"], sample_rate=sample[\"sampling_rate\"])\n","    batch[AUDIO_COLUMN_NAME][\"array\"] = augmented_waveform\n","    return batch"],"metadata":{"id":"BzBh2qwJmJtB"},"id":"BzBh2qwJmJtB","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### augment training data"],"metadata":{"id":"KU1PkVKpmdwo"},"id":"KU1PkVKpmdwo"},{"cell_type":"code","source":["preprocessing_num_workers = 4\n","\n","augmented_raw_training_dataset = raw_datasets[\"train\"].map(\n","    augment_dataset, num_proc=preprocessing_num_workers, desc=\"augment train dataset\"\n",")"],"metadata":{"id":"UHKUjGztmHuw"},"id":"UHKUjGztmHuw","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Combine raw data and augment data"],"metadata":{"id":"ccrCsBTbmSVH"},"id":"ccrCsBTbmSVH"},{"cell_type":"code","source":["datasets[\"train\"] = concatenate_datasets([datasets[\"train\"], augmented_raw_training_dataset])\n","datasets[\"train\"] = datasets[\"train\"].shuffle(seed=10)"],"metadata":{"id":"JN-hAMUumR96"},"id":"JN-hAMUumR96","execution_count":null,"outputs":[]},{"cell_type":"code","source":["datasets"],"metadata":{"id":"Avd2goHimbOp"},"id":"Avd2goHimbOp","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"cde6531c-eca0-4cd4-8d03-f89736023ee5","metadata":{"id":"cde6531c-eca0-4cd4-8d03-f89736023ee5"},"source":["## Preprocessing"]},{"cell_type":"code","execution_count":null,"id":"c1e832df-5454-4cd0-8331-2f47870df9db","metadata":{"id":"c1e832df-5454-4cd0-8331-2f47870df9db"},"outputs":[],"source":["from transformers.models.whisper.english_normalizer import BasicTextNormalizer\n","\n","normalizer = BasicTextNormalizer()"]},{"cell_type":"code","execution_count":null,"id":"e7008338-9d03-4105-b7b0-bb7e98e5a25c","metadata":{"id":"e7008338-9d03-4105-b7b0-bb7e98e5a25c"},"outputs":[],"source":["from transformers import WhisperProcessor\n","\n","processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\", language=\"french\", task=\"transcribe\")"]},{"cell_type":"code","execution_count":null,"id":"c9f4e685-100d-4b17-9196-9b2e17f477d2","metadata":{"id":"c9f4e685-100d-4b17-9196-9b2e17f477d2"},"outputs":[],"source":["do_normalize_text = True\n","\n","\n","def prepare_dataset(batch):\n","\n","    # load\n","    audio = batch[AUDIO_COLUMN_NAME]\n","\n","    # compute log-Mel input features from input audio array\n","    batch[\"input_features\"] = processor.feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n","\n","    # compute input length of audio sample in seconds\n","    batch[\"input_length\"] = len(audio[\"array\"]) / audio[\"sampling_rate\"]\n","\n","    # process targets\n","    input_str = normalizer(batch[TEXT_COLUMN_NAME]).strip() if do_normalize_text else batch[TEXT_COLUMN_NAME]\n","    \n","    # encode target text to label ids\n","    batch[\"labels\"] = processor.tokenizer(input_str).input_ids\n","\n","    return batch"]},{"cell_type":"code","execution_count":null,"id":"30da97e2-af05-4184-a7fc-b549c874a8ec","metadata":{"colab":{"referenced_widgets":["54904e31be95456d97948f5b7532e34f","55bc9de906284af8af2371a20782737f"]},"id":"30da97e2-af05-4184-a7fc-b549c874a8ec","outputId":"24d2a06e-36a2-4c49-8a62-3ad18da3d1e2"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"54904e31be95456d97948f5b7532e34f","version_major":2,"version_minor":0},"text/plain":["preprocess dataset:   0%|          | 0/200 [00:00<?, ?ex/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"55bc9de906284af8af2371a20782737f","version_major":2,"version_minor":0},"text/plain":["preprocess dataset:   0%|          | 0/50 [00:00<?, ?ex/s]"]},"metadata":{},"output_type":"display_data"}],"source":["vectorized_datasets = datasets.map(\n","    prepare_dataset, remove_columns=next(iter(datasets.values())).column_names, desc=\"preprocess dataset\"\n",")"]},{"cell_type":"markdown","id":"dcbb9469-c31c-4a6b-b28f-ea55c1d8551b","metadata":{"id":"dcbb9469-c31c-4a6b-b28f-ea55c1d8551b"},"source":["## Training and Evaluation"]},{"cell_type":"markdown","id":"6af1f413-cce6-4125-a950-cc91b52ba26d","metadata":{"id":"6af1f413-cce6-4125-a950-cc91b52ba26d"},"source":["### Data Collator"]},{"cell_type":"code","execution_count":null,"id":"8ad66769-9094-4bd9-9aa9-5b7a06d9a0b3","metadata":{"id":"8ad66769-9094-4bd9-9aa9-5b7a06d9a0b3"},"outputs":[],"source":["from dataclasses import dataclass\n","from typing import Any, Dict, List, Union\n","\n","@dataclass\n","class DataCollatorSpeechSeq2SeqWithPadding:\n","    processor: Any\n","\n","    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n","        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n","\n","        # convert to tensors\n","        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n","\n","        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n","        \n","        # pad label ids to the max length in the batch\n","        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n","\n","        # replace padding with -100 to ignore loss correctly\n","        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n","\n","        # if bos token is appended in previous tokenization step,\n","        # cut bos token here as it's append later anyways\n","        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n","            labels = labels[:, 1:]\n","\n","        batch[\"labels\"] = labels\n","\n","        return batch"]},{"cell_type":"code","execution_count":null,"id":"226fd7e2-9ba0-41ad-ae03-183eca100a82","metadata":{"id":"226fd7e2-9ba0-41ad-ae03-183eca100a82"},"outputs":[],"source":["data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)"]},{"cell_type":"markdown","id":"5b4e782e-5820-4233-841e-0b800acf5ee2","metadata":{"tags":[],"id":"5b4e782e-5820-4233-841e-0b800acf5ee2"},"source":["### Evaluation Metrics"]},{"cell_type":"code","execution_count":null,"id":"a4789691-1712-4c35-9c5f-88d3c150cac8","metadata":{"id":"a4789691-1712-4c35-9c5f-88d3c150cac8"},"outputs":[],"source":["import evaluate\n","\n","metric = evaluate.load(\"wer\")"]},{"cell_type":"code","execution_count":null,"id":"3c3669d1-e5d2-493e-b072-0ed184f541ed","metadata":{"id":"3c3669d1-e5d2-493e-b072-0ed184f541ed"},"outputs":[],"source":["# evaluate with the 'normalised' WER\n","do_normalize_eval = True\n","\n","\n","def compute_metrics(pred):\n","    pred_ids = pred.predictions\n","    label_ids = pred.label_ids\n","\n","    # replace -100 with the pad_token_id\n","    label_ids[label_ids == -100] = tokenizer.pad_token_id\n","\n","    # we do not want to group tokens when computing the metrics\n","    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n","    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n","\n","    if do_normalize_eval:\n","        pred_str = [normalizer(pred) for pred in pred_str]\n","\n","        # perhaps already normalised\n","        label_str = [normalizer(label) for label in label_str]\n","        \n","        # filtering step to only evaluate the samples that correspond to non-zero references\n","        pred_str = [pred_str[i] for i in range(len(pred_str)) if len(label_str[i]) > 0]\n","        label_str = [label_str[i] for i in range(len(label_str)) if len(label_str[i]) > 0]\n","\n","    wer = metric.compute(predictions=pred_str, references=label_str)\n","    return {\"wer\": wer}"]},{"cell_type":"markdown","id":"a4635b22-2fff-4340-b20e-98151e9d9a19","metadata":{"id":"a4635b22-2fff-4340-b20e-98151e9d9a19"},"source":["### Training Configuration"]},{"cell_type":"code","execution_count":null,"id":"c71ca560-0408-419a-8bdb-e88afb241035","metadata":{"id":"c71ca560-0408-419a-8bdb-e88afb241035"},"outputs":[],"source":["from transformers import Seq2SeqTrainingArguments\n","\n","training_args = Seq2SeqTrainingArguments(\n","    output_dir=\"./outputs/whisper_medium_ft\",\n","    per_device_train_batch_size=4,\n","    per_device_eval_batch_size=2,\n","    gradient_accumulation_steps=1,\n","    warmup_steps=30,\n","    max_steps=10,\n","    learning_rate=6.25e-2,\n","    weight_decay=0.01,\n","    gradient_checkpointing=True,\n","    fp16=True,\n","    predict_with_generate=True,\n","    generation_max_length=25,\n","    logging_steps=20,\n","    report_to=[\"tensorboard\"],\n","    evaluation_strategy=\"steps\",\n","    eval_steps=20,\n","    save_strategy=\"steps\",\n","    save_steps=20,\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"wer\",\n","    greater_is_better=False,\n",")"]},{"cell_type":"markdown","id":"c13d01c5-9d1b-4524-80cc-5f9c87b6b2de","metadata":{"id":"c13d01c5-9d1b-4524-80cc-5f9c87b6b2de"},"source":["### Initialize Trainer"]},{"cell_type":"code","execution_count":null,"id":"97ddfa78-47d5-4bfe-b471-6233ec69313f","metadata":{"id":"97ddfa78-47d5-4bfe-b471-6233ec69313f","outputId":"63e6221f-fd1e-4d21-8f87-b5f62debe016"},"outputs":[{"name":"stderr","output_type":"stream","text":["max_steps is given, it will override any value given in num_train_epochs\n","Using cuda_amp half precision backend\n"]}],"source":["from transformers import Seq2SeqTrainer\n","\n","trainer = Seq2SeqTrainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=vectorized_datasets[\"train\"],\n","    eval_dataset=vectorized_datasets[\"eval\"],\n","    tokenizer=processor,\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics,\n",")"]},{"cell_type":"markdown","id":"6ec8c90b","metadata":{"id":"6ec8c90b"},"source":["### GPU check again"]},{"cell_type":"code","execution_count":null,"id":"d76c3524","metadata":{"id":"d76c3524","outputId":"0290121a-cf98-4fe8-93ed-15ef2f8dac88"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using GPU is CUDA:1\n","CUDA:0 NVIDIA GeForce RTX 4090, 24195.125MB\n"]}],"source":["import os\n","\n","os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n","\n","print(f\"Using GPU is CUDA:{os.environ['CUDA_VISIBLE_DEVICES']}\")\n","\n","for i in range(torch.cuda.device_count()):\n","    info = torch.cuda.get_device_properties(i)\n","    print(f\"CUDA:{i} {info.name}, {info.total_memory / 1024 ** 2}MB\")\n","\n","device = torch.device(\"cuda:0\")"]},{"cell_type":"markdown","id":"62f7e022-624c-4e1f-a527-428c58056d68","metadata":{"id":"62f7e022-624c-4e1f-a527-428c58056d68"},"source":["### Training"]},{"cell_type":"code","execution_count":null,"id":"c19856d8-acdd-473a-b16c-7b6dae54cdf2","metadata":{"colab":{"referenced_widgets":["41e4eb8a49164efdbff4a34cb789d5ab"]},"id":"c19856d8-acdd-473a-b16c-7b6dae54cdf2","outputId":"3cf9dc45-a9ba-416e-c812-ae6d26717508"},"outputs":[{"name":"stderr","output_type":"stream","text":["The following columns in the training set don't have a corresponding argument in `WhisperForConditionalGeneration.forward` and have been ignored: input_length. If input_length are not expected by `WhisperForConditionalGeneration.forward`,  you can safely ignore this message.\n","/home/user/miniconda3/envs/asr_new/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 200\n","  Num Epochs = 1\n","  Instantaneous batch size per device = 4\n","  Total train batch size (w. parallel, distributed & accumulation) = 4\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 10\n","  Number of trainable parameters = 241734912\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"41e4eb8a49164efdbff4a34cb789d5ab","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/10 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["`use_cache = True` is incompatible with gradient checkpointing. Setting `use_cache = False`...\n","`use_cache = True` is incompatible with gradient checkpointing. Setting `use_cache = False`...\n","`use_cache = True` is incompatible with gradient checkpointing. Setting `use_cache = False`...\n","`use_cache = True` is incompatible with gradient checkpointing. Setting `use_cache = False`...\n","`use_cache = True` is incompatible with gradient checkpointing. Setting `use_cache = False`...\n","`use_cache = True` is incompatible with gradient checkpointing. Setting `use_cache = False`...\n","`use_cache = True` is incompatible with gradient checkpointing. Setting `use_cache = False`...\n","`use_cache = True` is incompatible with gradient checkpointing. Setting `use_cache = False`...\n","`use_cache = True` is incompatible with gradient checkpointing. Setting `use_cache = False`...\n","`use_cache = True` is incompatible with gradient checkpointing. Setting `use_cache = False`...\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"name":"stdout","output_type":"stream","text":["{'train_runtime': 9.4258, 'train_samples_per_second': 4.244, 'train_steps_per_second': 1.061, 'train_loss': 9.140096282958984, 'epoch': 0.2}\n"]}],"source":["train_result = trainer.train()"]},{"cell_type":"code","execution_count":null,"id":"6a724efc-4528-41ca-8817-c2a757f7a63c","metadata":{"id":"6a724efc-4528-41ca-8817-c2a757f7a63c","outputId":"06366258-b41e-45be-d8ce-827a6c0a4b04"},"outputs":[{"name":"stderr","output_type":"stream","text":["Configuration saved in ./outputs/whisper_medium_ft/config.json\n","Configuration saved in ./outputs/whisper_medium_ft/generation_config.json\n","Model weights saved in ./outputs/whisper_medium_ft/pytorch_model.bin\n","Feature extractor saved in ./outputs/whisper_medium_ft/preprocessor_config.json\n","tokenizer config file saved in ./outputs/whisper_medium_ft/tokenizer_config.json\n","Special tokens file saved in ./outputs/whisper_medium_ft/special_tokens_map.json\n","added tokens file saved in ./outputs/whisper_medium_ft/added_tokens.json\n"]}],"source":["model.save_pretrained(training_args.output_dir)\n","processor.save_pretrained(training_args.output_dir)"]},{"cell_type":"markdown","id":"df543330-5031-48b0-baad-ddff072ecaab","metadata":{"id":"df543330-5031-48b0-baad-ddff072ecaab"},"source":["## Evaluation"]},{"cell_type":"code","execution_count":null,"id":"fd63d822","metadata":{"id":"fd63d822","outputId":"cc07a47a-b761-4d2f-e5f7-0627ced04716"},"outputs":[{"name":"stderr","output_type":"stream","text":["loading file vocab.json from cache at /home/user/.cache/huggingface/hub/models--openai--whisper-small/snapshots/f6744499d1eba717bcf4d6be735e3d386ffb60ad/vocab.json\n","loading file tokenizer.json from cache at /home/user/.cache/huggingface/hub/models--openai--whisper-small/snapshots/f6744499d1eba717bcf4d6be735e3d386ffb60ad/tokenizer.json\n","loading file merges.txt from cache at /home/user/.cache/huggingface/hub/models--openai--whisper-small/snapshots/f6744499d1eba717bcf4d6be735e3d386ffb60ad/merges.txt\n","loading file normalizer.json from cache at /home/user/.cache/huggingface/hub/models--openai--whisper-small/snapshots/f6744499d1eba717bcf4d6be735e3d386ffb60ad/normalizer.json\n","loading file added_tokens.json from cache at /home/user/.cache/huggingface/hub/models--openai--whisper-small/snapshots/f6744499d1eba717bcf4d6be735e3d386ffb60ad/added_tokens.json\n","loading file special_tokens_map.json from cache at /home/user/.cache/huggingface/hub/models--openai--whisper-small/snapshots/f6744499d1eba717bcf4d6be735e3d386ffb60ad/special_tokens_map.json\n","loading file tokenizer_config.json from cache at /home/user/.cache/huggingface/hub/models--openai--whisper-small/snapshots/f6744499d1eba717bcf4d6be735e3d386ffb60ad/tokenizer_config.json\n","Adding <|startoftranscript|> to the vocabulary\n","Adding <|en|> to the vocabulary\n","Adding <|zh|> to the vocabulary\n","Adding <|de|> to the vocabulary\n","Adding <|es|> to the vocabulary\n","Adding <|ru|> to the vocabulary\n","Adding <|ko|> to the vocabulary\n","Adding <|fr|> to the vocabulary\n","Adding <|ja|> to the vocabulary\n","Adding <|pt|> to the vocabulary\n","Adding <|tr|> to the vocabulary\n","Adding <|pl|> to the vocabulary\n","Adding <|ca|> to the vocabulary\n","Adding <|nl|> to the vocabulary\n","Adding <|ar|> to the vocabulary\n","Adding <|sv|> to the vocabulary\n","Adding <|it|> to the vocabulary\n","Adding <|id|> to the vocabulary\n","Adding <|hi|> to the vocabulary\n","Adding <|fi|> to the vocabulary\n","Adding <|vi|> to the vocabulary\n","Adding <|he|> to the vocabulary\n","Adding <|uk|> to the vocabulary\n","Adding <|el|> to the vocabulary\n","Adding <|ms|> to the vocabulary\n","Adding <|cs|> to the vocabulary\n","Adding <|ro|> to the vocabulary\n","Adding <|da|> to the vocabulary\n","Adding <|hu|> to the vocabulary\n","Adding <|ta|> to the vocabulary\n","Adding <|no|> to the vocabulary\n","Adding <|th|> to the vocabulary\n","Adding <|ur|> to the vocabulary\n","Adding <|hr|> to the vocabulary\n","Adding <|bg|> to the vocabulary\n","Adding <|lt|> to the vocabulary\n","Adding <|la|> to the vocabulary\n","Adding <|mi|> to the vocabulary\n","Adding <|ml|> to the vocabulary\n","Adding <|cy|> to the vocabulary\n","Adding <|sk|> to the vocabulary\n","Adding <|te|> to the vocabulary\n","Adding <|fa|> to the vocabulary\n","Adding <|lv|> to the vocabulary\n","Adding <|bn|> to the vocabulary\n","Adding <|sr|> to the vocabulary\n","Adding <|az|> to the vocabulary\n","Adding <|sl|> to the vocabulary\n","Adding <|kn|> to the vocabulary\n","Adding <|et|> to the vocabulary\n","Adding <|mk|> to the vocabulary\n","Adding <|br|> to the vocabulary\n","Adding <|eu|> to the vocabulary\n","Adding <|is|> to the vocabulary\n","Adding <|hy|> to the vocabulary\n","Adding <|ne|> to the vocabulary\n","Adding <|mn|> to the vocabulary\n","Adding <|bs|> to the vocabulary\n","Adding <|kk|> to the vocabulary\n","Adding <|sq|> to the vocabulary\n","Adding <|sw|> to the vocabulary\n","Adding <|gl|> to the vocabulary\n","Adding <|mr|> to the vocabulary\n","Adding <|pa|> to the vocabulary\n","Adding <|si|> to the vocabulary\n","Adding <|km|> to the vocabulary\n","Adding <|sn|> to the vocabulary\n","Adding <|yo|> to the vocabulary\n","Adding <|so|> to the vocabulary\n","Adding <|af|> to the vocabulary\n","Adding <|oc|> to the vocabulary\n","Adding <|ka|> to the vocabulary\n","Adding <|be|> to the vocabulary\n","Adding <|tg|> to the vocabulary\n","Adding <|sd|> to the vocabulary\n","Adding <|gu|> to the vocabulary\n","Adding <|am|> to the vocabulary\n","Adding <|yi|> to the vocabulary\n","Adding <|lo|> to the vocabulary\n","Adding <|uz|> to the vocabulary\n","Adding <|fo|> to the vocabulary\n","Adding <|ht|> to the vocabulary\n","Adding <|ps|> to the vocabulary\n","Adding <|tk|> to the vocabulary\n","Adding <|nn|> to the vocabulary\n","Adding <|mt|> to the vocabulary\n","Adding <|sa|> to the vocabulary\n","Adding <|lb|> to the vocabulary\n","Adding <|my|> to the vocabulary\n","Adding <|bo|> to the vocabulary\n","Adding <|tl|> to the vocabulary\n","Adding <|mg|> to the vocabulary\n","Adding <|as|> to the vocabulary\n","Adding <|tt|> to the vocabulary\n","Adding <|haw|> to the vocabulary\n","Adding <|ln|> to the vocabulary\n","Adding <|ha|> to the vocabulary\n","Adding <|ba|> to the vocabulary\n","Adding <|jw|> to the vocabulary\n","Adding <|su|> to the vocabulary\n","Adding <|translate|> to the vocabulary\n","Adding <|transcribe|> to the vocabulary\n","Adding <|startoflm|> to the vocabulary\n","Adding <|startofprev|> to the vocabulary\n","Adding <|nocaptions|> to the vocabulary\n","Adding <|notimestamps|> to the vocabulary\n"]}],"source":["from transformers import WhisperTokenizer\n","\n","tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-small\",  language=\"french\", task=\"transcribe\")"]},{"cell_type":"code","execution_count":null,"id":"dde5955f-7901-4e34-a758-9736083c065c","metadata":{"colab":{"referenced_widgets":["5b1f170dc5f043c69150e772012e98ca"]},"id":"dde5955f-7901-4e34-a758-9736083c065c","outputId":"2a665b57-a2dd-4aa6-ce2c-f36a8a38f743"},"outputs":[{"name":"stderr","output_type":"stream","text":["The following columns in the evaluation set don't have a corresponding argument in `WhisperForConditionalGeneration.forward` and have been ignored: input_length. If input_length are not expected by `WhisperForConditionalGeneration.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 50\n","  Batch size = 2\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5b1f170dc5f043c69150e772012e98ca","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/25 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'eval_loss': 15.846515655517578,\n"," 'eval_wer': 1.0,\n"," 'eval_runtime': 11.0278,\n"," 'eval_samples_per_second': 4.534,\n"," 'eval_steps_per_second': 2.267,\n"," 'epoch': 0.2}"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["eval_metrics = trainer.evaluate(metric_key_prefix=\"eval\")\n","\n","eval_metrics"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"toc-showtags":false,"colab":{"provenance":[],"collapsed_sections":["a67eded3","b6d0a818-c6ad-488e-910c-ff32dcfa6356","cde6531c-eca0-4cd4-8d03-f89736023ee5","dcbb9469-c31c-4a6b-b28f-ea55c1d8551b","df543330-5031-48b0-baad-ddff072ecaab"]}},"nbformat":4,"nbformat_minor":5}